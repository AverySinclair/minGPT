{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('tf_2.2': conda)"
  },
  "interpreter": {
   "hash": "4b883466cadbb270d376cfa8984754c4c2daf33e6d178b272aa7f48bcc7ede88"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Train a GitHub copilot-style code completion model\n",
    "\n",
    "This trains a minimum viable character-level code completion model, similar to GitHub's copilot. The code in this notebook is based on Andrej Karpathy's `play_char` notebook, trained to complete Shakespeare test.\n",
    "\n",
    "A pretrained model is available [here](https://drive.google.com/file/d/1K_P0PYJBjanq8YTAzS8FF_kflcT9sOlI/view?usp=sharing), trained on my 8GB GTX 1070 for about 2 days. It spits out almost valid code, although isn't coming for anyone's job just yet. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make deterministic\n",
    "from mingpt.utils import set_seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Uncomment to download and extract data. Only necessary if retraining.'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "\"\"\"Uncomment to download and extract data. Only necessary if retraining.\"\"\"\n",
    "# !mkdir play_copilot_data\n",
    "# !wget https://s3.amazonaws.com/code-search-net/CodeSearchNet/v2/python.zip -P play_copilot_data/\n",
    "# !unzip play_copilot_data/python.zip -d play_copilot_data\n",
    "# !gzip -d -r play_copilot_data/python/final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Loading code into memory: 100%|██████████| 15/15 [00:19<00:00,  1.27s/it]\n",
      "Loading code into memory: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "435,285 training and 22,176 testing functions found.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "python_files_train = list(Path('play_copilot_data/python/final/jsonl/train/').glob('*.jsonl'))\n",
    "python_files_train += list(Path('play_copilot_data/python/final/jsonl/valid/').glob('*.jsonl'))\n",
    "python_files_test = list(Path('play_copilot_data/python/final/jsonl/test/').glob('*.jsonl'))\n",
    "\n",
    "def load_files(json_files):\n",
    "    \"\"\"Load raw data into list for training.\"\"\"\n",
    "    data = []\n",
    "    for f in tqdm(json_files, desc='Loading code into memory'):\n",
    "        with open(f, 'r') as fp:\n",
    "            file_data = fp.readlines()\n",
    "        data += [\n",
    "            str(json.loads(line)['code'].encode('ascii', 'ignore'))  # Drop non-ascii characters\n",
    "            for line in file_data if len(line) > 100\n",
    "        ]\n",
    "    return data\n",
    "\n",
    "train_data = load_files(python_files_train)\n",
    "test_data = load_files(python_files_test)\n",
    "\n",
    "print(f\"\\n{len(train_data):,} training and {len(test_data):,} testing functions found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CopilotDataset(Dataset):\n",
    "    \"\"\"Dataset for training a GitHub copilot-style code completion model.\n",
    "\n",
    "    `data` should be a list of strings where each item is a continuous\n",
    "    block of Python code, in all ASCII characters. In the data provided \n",
    "    in this notebook, each item is a complete function.\n",
    "\n",
    "    For every sample, a single function is loaded up and a random slice\n",
    "    is taken. Any padding applied is a null character, so that in the\n",
    "    future, you could generate data until a null character is returned.\n",
    "\n",
    "    Each sample is the converted to its ASCII character value, and the\n",
    "    model predicts a single character at a time.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, block_size):\n",
    "        self.vocab_size = 128  # Use all ascii characters\n",
    "        self.block_size = block_size\n",
    "        self.data = data\n",
    "        random.shuffle(self.data)\n",
    "\n",
    "        self.null = '\\x00'\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        chunk = self.data[idx]\n",
    "        chunklen = len(chunk)\n",
    "\n",
    "        # Get random slice of data, allowing ends to be overlapped\n",
    "        final_idx = np.random.randint(\n",
    "            self.block_size // 16, \n",
    "            chunklen + self.block_size // 16,\n",
    "        )\n",
    "\n",
    "        if final_idx > chunklen:\n",
    "            # Pad with null if selection is overrun\n",
    "            dix = chunk + self.null * (final_idx - chunklen)\n",
    "            first_idx = final_idx - self.block_size - 1\n",
    "            dix = dix[first_idx:final_idx]\n",
    "\n",
    "            # If chunk is still too short, add leading spaces\n",
    "            if len(dix) < self.block_size:\n",
    "                dix = self.null * (self.block_size - len(dix) + 1) + dix\n",
    "        \n",
    "        elif final_idx <= self.block_size:\n",
    "            # Pad with leading spaces if selection is too short\n",
    "            dix = chunk[:final_idx + 1]\n",
    "            dix = self.null * (self.block_size - len(dix) + 1) + dix\n",
    "  \n",
    "        elif final_idx > self.block_size:\n",
    "            first_idx = final_idx - self.block_size - 1\n",
    "            dix = chunk[first_idx:final_idx]\n",
    "        \n",
    "        dix = [ord(s) for s in dix]\n",
    "\n",
    "        x = torch.tensor(dix[:-1], dtype=torch.long)\n",
    "        y = torch.tensor(dix[1:], dtype=torch.long)\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "block_size = 512\n",
    "train_dataset = CopilotDataset(train_data, block_size)\n",
    "test_dataset = CopilotDataset(test_data, block_size)\n",
    "\n",
    "# Load pretrained model\n",
    "# Checkpoint available at https://drive.google.com/file/d/1K_P0PYJBjanq8YTAzS8FF_kflcT9sOlI/view?usp=sharing\n",
    "checkpoint_weights = 'play_copilot_ckpt_trn_0.4793_tst_0.4076.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "07/17/2021 14:30:06 - INFO - mingpt.model -   number of parameters: 2.561331e+07\n"
     ]
    }
   ],
   "source": [
    "from mingpt.model import GPT, GPTConfig\n",
    "mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size,\n",
    "                  n_layer=8, n_head=8, n_embd=512)\n",
    "model = GPT(mconf)\n",
    "\n",
    "if checkpoint_weights is not None:\n",
    "    model.load_state_dict(torch.load(checkpoint_weights))\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mingpt.trainer import Trainer, TrainerConfig\n",
    "\n",
    "# initialize a trainer instance and kick off training\n",
    "tconf = TrainerConfig(\n",
    "    max_epochs=10, \n",
    "    batch_size=12, \n",
    "    learning_rate=6e-4,\n",
    "    lr_decay=True, \n",
    "    warmup_tokens=512*20, \n",
    "    final_tokens=2*len(train_dataset)*block_size,\n",
    "    num_workers=4,\n",
    "    ckpt_path='play_copilot_checkpoint.pt',\n",
    ")\n",
    "trainer = Trainer(model, train_dataset, test_dataset, tconf)\n",
    "\n",
    "retrain = False\n",
    "if retrain:\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mingpt.utils import sample\n",
    "\n",
    "def sample_model(context, n_characters=500, temperature=1):\n",
    "    x = torch.tensor([ord(s) for s in context], dtype=torch.long)[None, ...].to(trainer.device)\n",
    "    y = sample(model, x, n_characters, temperature=1, sample=True, top_k=10)[0]\n",
    "    completion = ''.join([chr(i) for i in y])\n",
    "    completion = completion.replace('\\\\n', '\\n')\n",
    "\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "def multiply(x, y):\n    \"\"\"Multiply two numbers together.\"\"\"\n                    \"\"\"\n        if x < 0:\n            return\n        if y > 0:\n            temp = x                                             \"\"\"\n            temp = x - 1\n            y = y - 1.0\n            single = int(x ** 2 + 1)\n            for ind in temp:\n                if len(temp) % 10 == 0:\n                    single = -temp[ind+1]\n                    temp = y * (single - 1) % 10\n                    y = y                                   \"\"\"\n                    single = y - \n"
     ]
    }
   ],
   "source": [
    "print(sample_model('def multiply(x, y):\\n    \"\"\"Multiply two numbers together.\"\"\"\\n    ', temperature=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "def add(a, b):\n    \"\"\"Add an array to a sequence of arrays b to the collection. \"\"\"\n\n    sequence = []\n    for i in range(num_percent_sequences):\n        a_id = a << b\n        if a_id is not None:\n            sequence.append(sequence[i] * 2)\n            a_id = a_id\n            sequence.append(a_id)\n        a_array = a_id\n        a_array.append(num_array)\n        if not a_array:\n            a_array = a_array.replace(\\'\\\\t\\', \\'\\\\t\\')\n        #if not a_array:\n        #                            \n"
     ]
    }
   ],
   "source": [
    "print(sample_model('def add(a, b):', temperature=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    x = np.linspace(-10, 10, 1000)\n    y = np.sin(x) / x\n      # multiply this slice (or\n            (x.shape[1] >= node[\\'colormap\\']).sum())\n        else:\n            # slice the original slice before the slice was not set.\n            # It computes the single slice to set the sort of nodes,\n            # but this can be set up to 1000 seconds.\n            slice = (slice(x.shape[1]) - node[\\'shape\\']).sum()\n            x.start()\n            if slice is not None:\n                self.__slice_slices[slice] = slice.sort_keys == slice'\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\n"
     ]
    }
   ],
   "source": [
    "print(sample_model('    x = np.linspace(-10, 10, 1000)\\n    y = np.sin(x) / x\\n', temperature=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}